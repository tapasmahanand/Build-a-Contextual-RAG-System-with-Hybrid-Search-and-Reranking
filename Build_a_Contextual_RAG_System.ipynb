{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tapasmahanand/Build-a-Contextual-RAG-System-with-Hybrid-Search-and-Reranking/blob/main/Build_a_Contextual_RAG_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ],
      "metadata": {
        "id": "4vtFl39Ofu_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.4\n",
        "!pip install langchain-openai==0.2.3\n",
        "!pip install langchain-community==0.3.3\n",
        "!pip install jq==1.8.0\n",
        "!pip install pymupdf==1.24.12\n",
        "!pip install httpx==0.27.2"
      ],
      "metadata": {
        "id": "LVX6450Lfu_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Chroma Vector DB LangChain wrapper"
      ],
      "metadata": {
        "id": "bwUBYHjPfu_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-chroma==0.1.4"
      ],
      "metadata": {
        "id": "p30SmCgTfu__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install BM25 dependencies"
      ],
      "metadata": {
        "id": "_3X1I_Vj8aU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25==0.2.2"
      ],
      "metadata": {
        "id": "xdp84Y9w6H1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI API Key"
      ],
      "metadata": {
        "id": "EITC17hwfu__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ],
      "metadata": {
        "id": "yEh2olNvfvAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "pm_mx0v-fvAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ],
      "metadata": {
        "id": "Jhfb4gMUfvAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Processing the Data"
      ],
      "metadata": {
        "id": "afzeN_WkHIz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the dataset"
      ],
      "metadata": {
        "id": "RA_-hzHbFeSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you can't download using the following code\n",
        "# go to https://drive.google.com/file/d/1aZxZejfteVuofISodUrY2CDoyuPLYDGZ download it\n",
        "# manually upload it on colab\n",
        "!gdown 1aZxZejfteVuofISodUrY2CDoyuPLYDGZ"
      ],
      "metadata": {
        "id": "RZFMYH-yFhWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip rag_docs.zip"
      ],
      "metadata": {
        "id": "WwLEBC4nF9ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Process JSON Documents"
      ],
      "metadata": {
        "id": "wMlxKZ_5jIdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import JSONLoader\n",
        "\n",
        "loader = JSONLoader(file_path='./rag_docs/wikidata_rag_demo.jsonl',\n",
        "                    jq_schema='.',\n",
        "                    text_content=False,\n",
        "                    json_lines=True)\n",
        "wiki_docs = loader.load()"
      ],
      "metadata": {
        "id": "RZ5y0NfzHPhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(wiki_docs)"
      ],
      "metadata": {
        "id": "G4E1zYFSG7J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs[3]"
      ],
      "metadata": {
        "id": "aSbhERAyGw0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain.docstore.document import Document\n",
        "wiki_docs_processed = []\n",
        "\n",
        "for doc in wiki_docs:\n",
        "    doc = json.loads(doc.page_content)\n",
        "    metadata = {\n",
        "        \"title\": doc['title'],\n",
        "        \"id\": doc['id'],\n",
        "        \"source\": \"Wikipedia\",\n",
        "        \"page\": 1\n",
        "    }\n",
        "    data = ' '.join(doc['paragraphs'])\n",
        "    wiki_docs_processed.append(Document(page_content=data, metadata=metadata))"
      ],
      "metadata": {
        "id": "yICyAF85h2DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs_processed[3]"
      ],
      "metadata": {
        "id": "6IATrHWKh7II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Process PDF documents"
      ],
      "metadata": {
        "id": "F_GzvHP1jSBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "jxHHyhlbl_9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create chunk context generation chain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "\n",
        "def generate_chunk_context(document, chunk):\n",
        "\n",
        "    chunk_process_prompt = \"\"\"You are an AI assistant specializing in research paper analysis.\n",
        "                            Your task is to provide brief, relevant context for a chunk of text\n",
        "                            based on the following research paper.\n",
        "\n",
        "                            Here is the research paper:\n",
        "                            <paper>\n",
        "                            {paper}\n",
        "                            </paper>\n",
        "\n",
        "                            Here is the chunk we want to situate within the whole document:\n",
        "                            <chunk>\n",
        "                            {chunk}\n",
        "                            </chunk>\n",
        "\n",
        "                            Provide a concise context (3-4 sentences max) for this chunk,\n",
        "                            considering the following guidelines:\n",
        "\n",
        "                            - Give a short succinct context to situate this chunk within the overall document\n",
        "                            for the purposes of improving search retrieval of the chunk.\n",
        "                            - Answer only with the succinct context and nothing else.\n",
        "                            - Context should be mentioned like 'Focuses on ....'\n",
        "                            do not mention 'this chunk or section focuses on...'\n",
        "\n",
        "                            Context:\n",
        "                        \"\"\"\n",
        "\n",
        "    prompt_template = ChatPromptTemplate.from_template(chunk_process_prompt)\n",
        "\n",
        "    agentic_chunk_chain = (prompt_template\n",
        "                                |\n",
        "                            chatgpt\n",
        "                                |\n",
        "                            StrOutputParser())\n",
        "\n",
        "    context = agentic_chunk_chain.invoke({'paper': document, 'chunk': chunk})\n",
        "\n",
        "    return context"
      ],
      "metadata": {
        "id": "MHSh0Vg-mIUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import uuid\n",
        "\n",
        "def create_contextual_chunks(file_path, chunk_size=3500, chunk_overlap=0):\n",
        "\n",
        "    print('Loading pages:', file_path)\n",
        "    loader = PyMuPDFLoader(file_path)\n",
        "    doc_pages = loader.load()\n",
        "\n",
        "    print('Chunking pages:', file_path)\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
        "                                              chunk_overlap=chunk_overlap)\n",
        "    doc_chunks = splitter.split_documents(doc_pages)\n",
        "\n",
        "    print('Generating contextual chunks:', file_path)\n",
        "    original_doc = '\\n'.join([doc.page_content for doc in doc_chunks])\n",
        "    contextual_chunks = []\n",
        "    for chunk in doc_chunks:\n",
        "        chunk_content = chunk.page_content\n",
        "        chunk_metadata = chunk.metadata\n",
        "        chunk_metadata_upd = {\n",
        "            'id': str(uuid.uuid4()),\n",
        "            'page': chunk_metadata['page'],\n",
        "            'source': chunk_metadata['source'],\n",
        "            'title': chunk_metadata['source'].split('/')[-1]\n",
        "        }\n",
        "        context = generate_chunk_context(original_doc, chunk_content)\n",
        "        contextual_chunks.append(Document(page_content=context+'\\n'+chunk_content,\n",
        "                                          metadata=chunk_metadata_upd))\n",
        "    print('Finished processing:', file_path)\n",
        "    print()\n",
        "    return contextual_chunks"
      ],
      "metadata": {
        "id": "-uxOSfcsxqHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "pdf_files = glob('./rag_docs/*.pdf')\n",
        "pdf_files"
      ],
      "metadata": {
        "id": "i-VUpdmczt0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper_docs = []\n",
        "for fp in pdf_files:\n",
        "    paper_docs.extend(create_contextual_chunks(file_path=fp, chunk_size=3500))"
      ],
      "metadata": {
        "id": "EsicBMPazzlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(paper_docs)"
      ],
      "metadata": {
        "id": "oOkwPMxp0gFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper_docs[0]"
      ],
      "metadata": {
        "id": "qVK2i0lR0ieV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine all document chunks in one list"
      ],
      "metadata": {
        "id": "UyPdlZo2xEly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(wiki_docs_processed)"
      ],
      "metadata": {
        "id": "UbtpR-r50mEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_docs = wiki_docs_processed + paper_docs\n",
        "len(total_docs)"
      ],
      "metadata": {
        "id": "lNQWgq9t0pMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index Document Chunks and Embeddings in Vector DB\n",
        "\n",
        "Here we initialize a connection to a Chroma vector DB client, and also we want to save to disk, so we simply initialize the Chroma client and pass the directory where we want the data to be saved to."
      ],
      "metadata": {
        "id": "Daqn6Hglw9Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open AI Embedding Models\n",
        "\n",
        "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
      ],
      "metadata": {
        "id": "jiokYxD8fvAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
        "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
      ],
      "metadata": {
        "id": "-On4AS0HfvAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector DB Indexing for Semantic Search"
      ],
      "metadata": {
        "id": "wSbIwM4s5VBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# create vector DB of docs and embeddings - takes < 30s on Colab\n",
        "chroma_db = Chroma.from_documents(documents=total_docs,\n",
        "                                  collection_name='my_context_db',\n",
        "                                  embedding=openai_embed_model,\n",
        "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
        "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
        "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "                                  persist_directory=\"./my_context_db\")"
      ],
      "metadata": {
        "id": "ZhAQyrFBfvAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ju_zBIj1Zsb"
      },
      "source": [
        "### Load Vector DB from disk\n",
        "\n",
        "This is just to show once you have a vector database on disk you can just load and create a connection to it anytime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNvj0dDH1WDg"
      },
      "outputs": [],
      "source": [
        "# load from disk\n",
        "chroma_db = Chroma(persist_directory=\"./my_context_db\",\n",
        "                   collection_name='my_context_db',\n",
        "                   embedding_function=openai_embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFC3uPqYop0a"
      },
      "outputs": [],
      "source": [
        "chroma_db"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Similarity based Retrieval\n",
        "\n",
        "We use simple cosine similarity here and retrieve the top 5 similar documents based on the user input query"
      ],
      "metadata": {
        "id": "njfZOOVZxj1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
        "                                              search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "tV1l6HYdxj1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BM25 Indexing for Keyword based Retrieval"
      ],
      "metadata": {
        "id": "gsn6HfgA5Yc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents=total_docs,\n",
        "                                              k=5)\n",
        "bm25_retriever"
      ],
      "metadata": {
        "id": "vQKePy925MvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Retrieval Strategy"
      ],
      "metadata": {
        "id": "zxa3xf_D6SYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Base Ensemble Retriever"
      ],
      "metadata": {
        "id": "5AetRdtr6W_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "# reciprocal rank fusion\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, similarity_retriever],\n",
        "    weights=[0.5, 0.5]\n",
        ")\n",
        "ensemble_retriever"
      ],
      "metadata": {
        "id": "738cpSm_5SQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chained Retrieval with Reranker"
      ],
      "metadata": {
        "id": "DteKLQTM7EnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "\n",
        "# download an open-source reranker model - BAAI/bge-reranker-v2-m3\n",
        "reranker = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
        "reranker_compressor = CrossEncoderReranker(model=reranker, top_n=5)\n",
        "# Retriever 2 - Uses a Reranker model to rerank retrieval results from the previous retriever\n",
        "final_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=reranker_compressor,\n",
        "    base_retriever=ensemble_retriever\n",
        ")\n",
        "final_retriever"
      ],
      "metadata": {
        "id": "OhnRVwst7D_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_docs(docs):\n",
        "    for doc in docs:\n",
        "        print('Metadata:', doc.metadata)\n",
        "        print('Content Brief:')\n",
        "        display(Markdown(doc.page_content[:1000]))\n",
        "        print()"
      ],
      "metadata": {
        "id": "nUIJG_bDxj1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is machine learning?\"\n",
        "top_docs = final_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "id": "PIh4xGv2xj1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the difference between transformers and vision transformers?\"\n",
        "top_docs = final_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "id": "S_PXFMcJxuyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the RAG Pipeline"
      ],
      "metadata": {
        "id": "gQFWv7YUyVII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
        "                Answer the following question using only the following pieces of retrieved context.\n",
        "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
        "                Keep the answer detailed and well formatted based on the information from the context.\n",
        "\n",
        "                Question:\n",
        "                {question}\n",
        "\n",
        "                Context:\n",
        "                {context}\n",
        "\n",
        "                Answer:\n",
        "            \"\"\"\n",
        "\n",
        "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
      ],
      "metadata": {
        "id": "PHOrfGXKyVIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "qa_rag_chain = (\n",
        "    {\n",
        "        \"context\": (final_retriever\n",
        "                      |\n",
        "                    format_docs),\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "      |\n",
        "    rag_prompt_template\n",
        "      |\n",
        "    chatgpt\n",
        ")"
      ],
      "metadata": {
        "id": "KmWeCB4yyVIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "query = \"What is machine learning?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "xvj_eGIWyVIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a CNN?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "pXtezDlZzadt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is a resnet better than a CNN?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "Fo92-ZmIELPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is NLP and its relation to linguistics?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "J5IQoBc0zlAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the difference between AI, ML and DL?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "AzeZuG1hzvGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the difference between transformers and vision transformers?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "cWihDiL3zPzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is self-attention important in transformers?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "k1lqzejlEvsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How does a resnet work?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "7Zf_BjmlFBcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is LangChain?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "id": "Ttz53mEy0J_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}